# -*- coding: utf-8 -*-
"""full_recommender.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_bZUB6P16ulWLUYgdwgE3xqlbHyBOCtU
"""

#importing libraries
import pandas as pd
import numpy as np
import sklearn
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

#reading the posts table
l_posts = pd.read_json('json_data/lucid_table_posts.json',orient='columns')

#reading the notifications table
l_nots = pd.read_json('json_data/lucid_table_notifications.json',orient='columns')

#reading the following  table
l_follow =  pd.read_json('json_data/lucid_table_following.json',orient='columns')

#reading the thoughts table
l_thoughts =  pd.read_json('json_data/lucid_table_thoughts.json',orient='columns')

#reading the users table
l_users =  pd.read_json('json_data/lucid_table_users.json',orient='columns')

#displaying first 3 rows in the posts table 
l_posts.head(3)

#selecting the columns needed in the posts table
posts = l_posts[['id','user_id','title']]
posts.head()

#displaying first 3 rows in the notifications table 
l_nots.head(3)

#selecting the columns needed in the notifications table
notifs = l_nots[['id', 'user_id', 'action']]
notifs.head()

"""# MOST POPULAR ARTICLES"""

#merging posts and notifications table 
pop_articles = posts.merge(notifs, on='user_id')

#grouping the most followed people by name and their follower_id in descending ordrer
pop_articles = pop_articles.groupby('title')['action'].count().sort_values(ascending=False)
print("TOP 10 RECOMMENDATIONS BASED ON MOST POPULAR ARTICLES\n")
print(pop_articles.head(10))

"""#CONTENT BASED RECOMMENDER"""

#displaying first 10 rows in title column in the posts table
posts['title'].head(10)

#Remove all english stop words such as 'the', 'a'
tfidf = TfidfVectorizer(stop_words='english')

#Construct the required TF-IDF matrix by fitting and transforming the data
tfidf_matrix = tfidf.fit_transform(posts['title'])

# Compute the cosine similarity matrix
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)

#Construct a reverse map of indices and post titles
indices = pd.Series(posts.index, index=posts['title']).drop_duplicates()

# function that takes in a post title as an input
# this is when a user clicks on an article

def get_recommendations(title, cosine_sim=cosine_sim):
  
  try:
    idx = indices[title]

    # Get the pairwsie similarity scores of all movies with that movie
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Sort the posts based on the similarity scores
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Get the scores of the 10 most similar posts
    sim_scores = sim_scores[1:11]

    # Get the post indices
    post_indices = [i[0] for i in sim_scores]

    # Return the top 10 most similar posts
    print("RECOMMENDATIONS BASED ON YOUR READING PATTERN\n")
    return posts['title'].iloc[post_indices]
  
  except KeyError:
    print("We Have No Recommendations For You!")

get_recommendations('First HTML Project')